---
title: "IO: C∆° ch·∫ø blk-mq (Block IO Layer Multi-Queue) trong nh√¢n Linux (Ph·∫ßn 2)"
author: kiennql
date: 2025-06-21 15:21:00 +0700
categories: [io, kernel]
tags: [linux, kernel, blk-mq, block-io, multi-queue, storage, nvme, performance]
math: true
mermaid: true
render_with_liquid: false
---

## 1. Gi·ªõi thi·ªáu

B√†i vi·∫øt n√†y tr∆∞·ªõc ti√™n s·∫Ω gi·ªõi thi·ªáu ng·∫Øn g·ªçn v·ªÅ framework `blk-mq` t·ª´ g√≥c ƒë·ªô b·ªëi c·∫£nh v√† ki·∫øn tr√∫c, sau ƒë√≥ s·∫Ω ƒëi s√¢u h∆°n v√†o c∆° ch·∫ø tri·ªÉn khai n·ªôi b·ªô th√¥ng qua c·∫•u tr√∫c d·ªØ li·ªáu v√† c√°c lu·ªìng c·ª• th·ªÉ.

## 2. B·ªëi c·∫£nh

### 2.1. blk-mq l√† g√¨?

> The Multi-Queue Block IO Queueing Mechanism is an API to enable fast storage devices to achieve a huge number of input/output operations per second (IOPS) through queueing and submitting IO requests to block devices simultaneously, benefiting from the parallelism offered by modern storage devices.

**TL;DR** `blk-mq` l√† framework multi-queue IO c·ªßa block layer trong kernel, ph√π h·ª£p v·ªõi c√°c thi·∫øt b·ªã l∆∞u tr·ªØ multi-queue c√≥ y√™u c·∫ßu IOPS cao.

### 2.2. T·∫°i sao c·∫ßn blk-mq?

![bottleneck](/assets/img/post/linux-blk-mq-mechanism/blk-mq-bottleneck.png)
_Software bottleneck_

L√Ω do ch√≠nh l√† s·ª± ph√°t tri·ªÉn c·ªßa multi-core v√† multi-queue, khi·∫øn bottleneck hi·ªáu su·∫•t chuy·ªÉn t·ª´ ph·∫ßn c·ª©ng sang ph·∫ßn m·ªÅm: single-queue framework g·∫∑p v·∫•n ƒë·ªÅ v·ªÅ lock contention v√† remote memory access. Do ƒë√≥, vi·ªác t√°i c·∫•u tr√∫c l√† c·∫ßn thi·∫øt.

![benchmark-IOPS](/assets/img/post/linux-blk-mq-mechanism/blk-mq-benchmark-IOPS.png)
![benchmark-latency](/assets/img/post/linux-blk-mq-mechanism/blk-mq-benchmark-latency.png)

Trong benchmark c·ª• th·ªÉ, c√≥ th·ªÉ th·∫•y single-queue framework (SQ) kh√¥ng th·ªÉ ƒë√°p ·ª©ng ƒë∆∞·ª£c s·ª± ph√°t tri·ªÉn c·ªßa ph·∫ßn c·ª©ng v·ªÅ m·∫∑t kh·∫£ nƒÉng m·ªü r·ªông.

## 3. T·ªïng quan Framework

![overview](/assets/img/post/linux-blk-mq-mechanism/blk-mq-overview.png)

ƒê·ªÉ gi·∫£m lock contention v√† t·∫≠n d·ª•ng t·ªëi ƒëa locality principle, `blk-mq` t√°ch single queue v·ª´a ch·ªãu tr√°ch nhi·ªám submit v·ª´a dispatch th√†nh multi-level v√† multi-queue.

Framework `blk-mq` c√≥ 2 lo·∫°i queue:

- **Software Staging Queue** c·∫•p per-cpu
  - Th∆∞·ªùng ƒë∆∞·ª£c g·ªçi l√† software queue, software staging queue, ctx (context)
  - T∆∞∆°ng ·ª©ng v·ªõi c·∫•u tr√∫c d·ªØ li·ªáu `blk_mq_ctx`

- **Hardware Dispatch Queue** t∆∞∆°ng ·ª©ng v·ªõi hardware queue c·ªßa thi·∫øt b·ªã l∆∞u tr·ªØ
  - Th∆∞·ªùng c√≥ c√°c t√™n g·ªçi k·ª≥ l·∫° nh∆∞ hardware queue, hctx (hardware context), hwq
  - T∆∞∆°ng ·ª©ng v·ªõi c·∫•u tr√∫c d·ªØ li·ªáu `blk_mq_hw_ctx`
  - Request v√†o queue n√†y c√≥ nghƒ©a l√† ƒë√£ ƒë∆∞·ª£c scheduling

M·ªói thi·∫øt b·ªã l∆∞u tr·ªØ c√≥ m·ªôt controlling structure l√† `blk_mq_tag_set`, d√πng ƒë·ªÉ duy tr√¨ m·ªëi quan h·ªá gi·ªØa c√°c queue:

- **Field**: `.mq_maps`
  - **Type**: `int*`, th·ª±c t·∫ø s·ª≠ d·ª•ng nh∆∞ array `int[]` v·ªõi ƒë·ªô d√†i b·∫±ng s·ªë CPU
  - **Purpose**: Th·ª±c hi·ªán mapping t·ª´ CPU ƒë·∫øn hardware queue
  - **Note**: Index l√† CPU number, gi√° tr·ªã t∆∞∆°ng ·ª©ng l√† hardware queue number ƒë∆∞·ª£c map. V√≠ d·ª• `set->mq_map[cpu_j] = hw_queue_i`, trong ƒë√≥ i v√† j kh√¥ng li√™n quan

- **Field**: `.tags`
  - **Type**: `blk_mq_tags**`, th·ª±c t·∫ø s·ª≠ d·ª•ng nh∆∞ array `(blk_mq_tags*)[]` v·ªõi ƒë·ªô d√†i b·∫±ng s·ªë CPU
  - **Purpose**: Qu·∫£n l√Ω ph√¢n b·ªï request, ph√¢n b·ªï `set->tags[hw_queue_id]` cho m·ªói hwq

Hardware queue ƒë∆∞·ª£c li√™n k·∫øt v·ªõi tag (t·ª´ ƒë√≥ gi√°n ti·∫øp li√™n k·∫øt v·ªõi `request`), c·∫•u tr√∫c t∆∞∆°ng ·ª©ng l√† `blk_mq_tags`:

- **Field**: `.static_rqs`
  - **Type**: `request**`, th·ª±c t·∫ø s·ª≠ d·ª•ng nh∆∞ array `(request*)[]` v·ªõi ƒë·ªô d√†i b·∫±ng queue depth parameter `set->queue_depth`
  - **Purpose**: Pre-allocate `set->queue_depth` request instances t·ª´ buddy, ch·ªù s·ª≠ d·ª•ng sau n√†y
  - **Note**: Array n√†y c·∫ßn tag allocation, s·ª≠ d·ª•ng bitmap (sbitmap) ƒëi k√®m ƒë·ªÉ nhanh ch√≥ng l·∫•y free tag. M·ªói l·∫ßn dispatch request tr∆∞·ªõc ti√™n c·∫ßn l·∫•y tag ƒë·ªÉ bind

- **Field**: `.rqs`
  - **Type**: `request**`, th·ª±c t·∫ø s·ª≠ d·ª•ng nh∆∞ array `(request*)[]` v·ªõi ƒë·ªô d√†i b·∫±ng queue depth parameter `set->queue_depth`
  - **Purpose**: Request instance l·∫•y t·ª´ `static_rqs[tag]` trong non-elevator scheduling s·∫Ω ƒë∆∞·ª£c ƒë·∫∑t v√†o array n√†y (c√πng index), bi·ªÉu th·ªã in-flight request
  - **Note**: Th·ª±c t·∫ø t√¥i kh√¥ng bi·∫øt ƒë·ªÉ l√†m g√¨, m·ªôt kh·∫£ nƒÉng l√† cung c·∫•p iterator cho driver ƒë·ªÉ duy·ªát t·∫•t c·∫£ request ƒëang s·ª≠ d·ª•ng

M·ªëi quan h·ªá gi·ªØa tag-set v√† ctx c√≥ th·ªÉ xem trong h√¨nh d∆∞·ªõi:

![tag](/assets/img/post/linux-blk-mq-mechanism/blk-mq-tag-set.png)
![ctx](/assets/img/post/linux-blk-mq-mechanism/blk-mq-ctx.png)

## 4. Kh·ªüi t·∫°o Framework

### 4.1. Lu·ªìng nvme_probe

Framework `blk-mq` ho√†n th√†nh kh·ªüi t·∫°o ·ªü driver layer, l·∫•y nvme device l√†m v√≠ d·ª•, giai ƒëo·∫°n kh·ªüi t·∫°o chia th√†nh upper v√† lower half. Upper half b·∫Øt ƒë·∫ßu t·ª´ function `nvme_probe`:

```c
nvme_probe(...)
    dev = kzalloc_node(...)
    ...
    INIT_WORK(..., nvme_reset_work)

// Trong async flow
nvme_reset_work(work)
    dev = container_of(work, ...)
    ...
    nvme_dev_add(dev)
    ...

nvme_dev_add(dev)
    dev->tagset.ops = nvme_mq_ops
    dev->tagset.nr_hw_queues = ...
        // S·ªë hwq cu·ªëi c√πng s·∫Ω b·ªã gi·ªõi h·∫°n ƒë·∫øn min(s·ªë hardware queue, s·ªë CPU)
    dev->tagset.queue_depth = min(dev->q_dep, 10240) - 1
        // ·ªû ƒë√¢y queue depth c·ªßa tagset ch∆∞a ƒë∆∞·ª£c x√°c ƒë·ªãnh cu·ªëi c√πng, n·∫øu qu√° tr√¨nh construct sau n√†y th·∫•t b·∫°i, 
        // kernel s·∫Ω th·ª≠ gi·∫£m depth m·ªôt n·ª≠a v√† retry, cho ƒë·∫øn khi depth ch·ªâ c√≤n 1
    dev->tagset.flags = BLK_MQ_F_SHOULD_MERGE
    blk_mq_alloc_tag_set(alias set = dev->tagset)
        set->tags = kcalloc_node(nr_cpu_ids, sizeof *, ...)
            // ·ªû ƒë√¢y cho th·∫•y tags l√† array v·ªõi element type l√† blk_mq_tags*, length l√† s·ªë CPU
        set->mq_map = kcalloc_node(nr_cpu_ids, sizeof, ...)
            // mq_map l√† array v·ªõi element type l√† int, length l√† s·ªë CPU
        blk_mq_update_queue_map(set)
            // Qu√° tr√¨nh n√†y ho√†n th√†nh mapping t·ª´ CPU ƒë·∫øn hw queue
            for-each cpu: set->mq_map[cpu] = 0
            set->ops->map_queues(ret)
                // T∆∞∆°ng ·ª©ng v·ªõi implementation nvme_pci_map_queues
                for-each hwq: for-each cpu-in-mask: set->mq_map[cpu] = queue
        blk_mq_alloc_rq_maps(set)
            // Construct set->tags[0...hctx_max-1]
            // B·ªè qua tr∆∞·ªùng h·ª£p ƒë·∫∑c bi·ªát depth gi·∫£m m·ªôt n·ª≠a
            for-each hwq, i: __blk_mq_alloc_rq_map(set, alias hctx_idx = i)
                // Construct set->tags[hctx_idx]
                set->tags[hctx_idx] = blk_mq_alloc_rq_map(set, hctx_id, ...)
                    // L·∫•y numa_node node
                    // ƒê·ªãnh nghƒ©a (t∆∞∆°ng ·ª©ng queue) tags = blk_mq_init_tags(...)
                        // X√°c nh·∫≠n tags->nr_tags v√† tags_nr_reserved_tags
                        // c≈©ng nh∆∞ construct sbitmap
                    tags->rqs = kcalloc_node(nr_tags, sizeof *)
                        // rqs l√† array v·ªõi element type l√† request* v·ªõi length l√† queue depth
                    tags->static_rqs = kcalloc_node(nr_tags, sizeof *)
                    return tags
                blk_mq_alloc_rqs(set, set->tags[hctx_id], hctx_id, queue_depth)
                    // Construct tags->page_list, theo queue depth d nh√¢n request size c√≥ payload v·ªõi d,
                    // allocate page t∆∞∆°ng ·ª©ng t·ª´ buddy, v√† s·ª≠ d·ª•ng virtual address c·ªßa page
                    // l∆∞u v√†o static_rqs[...], trong ƒë√≥ nhi·ªÅu page c√≥ th·ªÉ traverse qua page_list
                    // Sau khi allocate request, c√≥ th·ªÉ t·ª´ set->ops->init_request custom initialize request
    dev->ctrl.tagset = dev->tagset
```

### 4.2. Lu·ªìng nvme_alloc_ns

Lower half c√≥ caller call stack nh∆∞ sau:

```c
nvme_alloc_ns
nvme_validate_ns
nvme_scan_ns_list
nvme_scan_work(async)
nvme_init_ctrl
```

Trong ƒë√≥, `nvme_init_ctrl` s·ª≠ d·ª•ng `workqueue` ƒë·ªÉ async trigger `nvme_scan_work`.

```c
nvme_alloc_ns(ctrl, nsid)
    nvme_ns *ns = kzalloc_node(...)
    ns->queue = blk_mq_init_queue(ctrl->tagset) ‚≠ê
    ns->queue->queuedata = ns
    ns->ctrl = ctrl
    ...
    disk = alloc_disk_node(...)
    disk->fops = nvme_fops
    disk->private_data = ns
    disk->queue = ns->queue
    ns->disk = disk
    ...
```

C√≥ th·ªÉ th·∫•y ·ªü ƒë√¢y ch√≠nh th·ª©c v√†o framework `blk-mq`, v√† `tagset` ƒë√£ construct ·ªü upper half c≈©ng ƒë∆∞·ª£c truy·ªÅn v√†o framework. Ngo√†i ra, `gendisk` c≈©ng thi·∫øt l·∫≠p association v·ªõi `nvme`, ph·∫ßn li√™n quan ƒë·∫øn `blk-mq` l√† `disk->queue` ƒë·∫øn t·ª´ `ns` v√† ƒë∆∞·ª£c construct qua framework `blk-mq`.

### 4.3. Lu·ªìng blk_mq_init_queue

Lu·ªìng n√†y l√† initialization flow c·ªßa `request_queue`, li√™n quan ƒë·∫øn `ctx` v√† `hctx` ƒë∆∞·ª£c bind v·ªõi n√≥.

````c
blk_mq_init_queue(set)
    q = blk_alloc_queue_node(GFP_KERNEL, ...)
        // B·ªè qua, ch·ªâ return m·ªôt request queue ƒë√£ allocate nh∆∞ng ch∆∞a (ho√†n to√†n) construct
    return blk_mq_init_allocated_queue(set, q)
        q->mq_ops = set->ops
        q->queue_ctx = alloc_percpu(...)
        q->queue_hw_ctx = kcalloc_node(nr_cpu_ids)
            // hwctx l√† array v·ªõi element l√† pointer, length l√† s·ªë CPU
        q->mq_map = set->mq_map
        blk_mq_realloc_hw_ctxes(set, q)
            // ·ªû ƒë√¢y th·ª±c t·∫ø allocate hctx instance
            for-each(i, 0, set->nr_hw_queues)
                // Ch·ªâ cho empty hctxs[i]
                hctxs[i] = kzalloc_node(...)
                blk_mq_init_hctx(q, set, hctxs[i], alias hctx_idx = i)
                    hctx->queue = q
                    hctx->flag &= ~shared
                    hctx->tags = set->tags[hctx_idx]
                    hctx->ctxs = kmalloc_array_node(nr_cpu_ids, sizeof *)
                    hctx->nr_ctx = 0
                    set->ops->init_hctx(hctx, ...)
                        // V·ªõi nvme ch·ªß y·∫øu l√† thi·∫øt l·∫≠p m·ªëi quan h·ªá gi·ªØa nvme_queue ·ªü driver layer v√† hctx
                    blk_mq_sched_init_hctx(q, hctx, hctx_idx)
                        // Construct hctx->sched_tags
                        elevator e = q->elevator
                        blk_mq_sched_alloc_tags(q, hctx, hctx_id)
                            hctx->sched_tags = blk_mq_alloc_rq_map()
                                // L·∫∑p l·∫°i, xem nvme flow, construct t·ª´ng element instance c·ªßa sched_tags[...]
                            blk_mq_alloc_rqs(set, hctx->sched_tags, ...)
                                // L·∫∑p l·∫°i, xem nvme flow, li√™n quan ƒë·∫øn static_rq
                        e->type->ops.mq.init_hctx(...)
                            // T∆∞∆°ng t·ª±, ch·ªâ l√† chuy·ªÉn th√†nh sched_tag
                    hctx->fq = ...
                    blk_mq_init_request()
                        // L·∫∑p l·∫°i, b·ªè qua
            // TODO: ·ªû ƒë√¢y s·∫Ω c√≥ construct hctx c·ªßa scheduling layer
        q->nr_queues = nr_cpu_ids
        blk_queue_make_request
            // ƒêƒÉng k√Ω callback q->make_request_fn th√†nh blk_mq_make_request
        q->nr_batching = BLK_BATCH_REQ = 32
        q->nr_request = set->queue_depth
        blk_mq_init_cpu_queues(q, set->nr_hw_queues)
            for-each cpu, i:
                // L·∫•y percpu ctx
                ctx->cpu = i
                ctx->queue = q
                ...
        blk_mq_add_queue_tag_set(set, q)
            // V·ªÅ c∆° b·∫£n l√† li√™n k·∫øt q->tag_set = set
            // v√† x·ª≠ l√Ω hctx trong shared mode, b·ªè qua
        blk_mq_map_swqueue(q)
            // X·ª≠ l√Ω mapping t·ª´ software queue ƒë·∫øn hardware queue
            for-each cpu, i:
                hctx_id = q->mq_map[i]
                    // L·∫•y mapping ID t·ª´ CPU ƒë·∫øn hctx t·ª´ map
                hctx = q->queue_hw_ctx[q->mq_map[cpu]]
                cpumask_set_cpu(i, hctx->cpumask)
                ctx->index_hw = hctx->nr_ctx
                hctx->ctxes[hctx->nr_ctx++] = ctx
                    // M·ªôt hctx c√≥ th·ªÉ t∆∞∆°ng ·ª©ng v·ªõi nhi·ªÅu ctx, do ƒë√≥ d√πng index_hw ƒë·ªÉ bi·ªÉu th·ªã index c·ªßa ctx trong hctx->ctxes[]
                for-each hctx(q, hctx, i):
                    hctx->tags = set->tags[i]
                    ...
        elevator_init_mq(q)
            // Ch·ªçn elevator m·∫∑c ƒë·ªãnh
            // Single queue ch·ªçn mq-deadline
            // Multi queue ho·∫∑c kh√¥ng c√≥ mq-deadline th√¨ ch·ªçn none
        return q
```

## 5. Lu·ªìng IO c·ªßa Framework

### 5.1. Lu·ªìng submit IO

C√°c thao t√°c IO t·ª´ userspace s·∫Ω ƒë∆∞·ª£c m√¥ t·∫£ b·∫±ng c·∫•u tr√∫c `bio`, v√† trong kernel s·∫Ω ƒë∆∞·ª£c submit th√¥ng qua interface th·ªëng nh·∫•t `submit_bio`.

```c
submit_bio(bio)
    ...
    // IO accounting stuff
    ...
    return generic_make_request_(bio)
        q = bio->bi_disk->queue
        ...
        // workaround for stacked devices
        ...
        return q->make_request_fn(q, bio) ‚≠ê
```

T·ª´ lu·ªìng tr∆∞·ªõc c√≥ th·ªÉ bi·∫øt, instance `make_request_fn` ƒë∆∞·ª£c ƒëƒÉng k√Ω trong `blk-mq` l√† `blk_mq_make_request`.

```c
blk_mq_init_allocated_queue()
    ...
    blk_queue_make_request(q, blk_mq_make_request)
        // set default blk-mq limits
        q->make_request_fn = blk_mq_make_request
    ...
```

### 5.2. Lu·ªìng x·ª≠ l√Ω IO

X·ª≠ l√Ω IO n√≥i ƒë∆°n gi·∫£n l√† chuy·ªÉn ƒë·ªïi `bio` th√†nh c·∫•u tr√∫c `request` v√† insert v√†o request queue. So v·ªõi submit IO ƒë∆∞·ª£c th·ª±c hi·ªán tr√™n kernel stack c·ªßa process hi·ªán t·∫°i, x·ª≠ l√Ω IO c√≤n c√≥ th·ªÉ ƒë∆∞·ª£c th·ª±c hi·ªán async trong kernel thread `kblockd`.

```c
blk_mq_make_request(q, bio)
    // Th·ª±c hi·ªán bio split theo y√™u c·∫ßu (th∆∞·ªùng theo gi·ªõi h·∫°n ph·∫ßn c·ª©ng/ph·∫ßn m·ªÅm)
    // Merge v√†o plug queue c·ªßa process theo y√™u c·∫ßu, th√†nh c√¥ng th√¨ k·∫øt th√∫c
        // precondition: !FLUSH_FUA && !NOMERGE
    blk_mq_sched_bio_merge
        // Th·ª≠ merge v·ªõi pending request trong sched queue, th√†nh c√¥ng th√¨ return
    wbt_wait
        // Khi v∆∞·ª£t qu√° writeback limit, cung c·∫•p blocking point t·∫°i ƒë√¢y
    blk_mq_get_request
        // Return m·ªôt request, c·∫ßn s·ª≠ d·ª•ng k·∫øt h·ª£p static_rqs v√† sbitmap
        // note: merge theo y√™u c·∫ßu ·ªü tr√™n kh√¥ng ho√†n th√†nh, do ƒë√≥ c·∫ßn request
    // Ph√¢n nh√°nh ƒëi·ªÅu ki·ªán:
        // 1. flush or fua
            // C·∫ßn dispatch nhanh ch√≥ng, b·ªè qua scheduler, request insert v√†o flush queue ri√™ng, wake up th·ª±c thi hctx
        // 2. plug && q->nr_hw_queues == 1
            // Single queue device v√† plug th√¨ add v√†o mq_list c·ªßa plug
        // 3. plug && !no_merge
            // T∆∞∆°ng t·ª± case2, nh∆∞ng ƒë√¢y l√† plug c·ªßa multi-queue, b·ªè qua
        // 4. q->nr_hw_queues > 1 && sync
            // Multi-queue, kh√¥ng c√≥ plug ƒëi blk_mq_try_issue_directly
            // V·ªõi read operation, n√™n √°p d·ª•ng ·ªü ƒë√¢y
        // 5. others
            // ƒêi blk_mq_sched_insert_request
            // ·ªû ƒë√¢y s·∫Ω ti·∫øp t·ª•c ph√¢n chia tr∆∞·ªùng h·ª£p, v√≠ d·ª• c√≥ flush hay kh√¥ng, c√≥ elevator hay kh√¥ng

// N·∫øu l√† case4:
    // Tr∆∞·ªùng h·ª£p non-elevator, ƒëi th·∫≥ng ƒë·∫øn h√†m enqueue do driver layer cung c·∫•p
    // Ng∆∞·ª£c l·∫°i, ƒëi elevator sched_insert

// N·∫øu l√† case5:
    // Tr∆∞·ªùng h·ª£p non-elevator, s·∫Ω insert v√†o ctx queue
    // Ng∆∞·ª£c l·∫°i, ƒëi elevator sched_insert

// C√≤n c·∫ßn xem setting run_queue, n·∫øu c√≥, ti·∫øp theo blk_mq_run_hw_queue th·ª±c thi hctx ƒë·ªÉ batch dispatch IO
// Th∆∞·ªùng th√¨ run_queue = true, tr·ª´ khi driver layer th√¥ng b√°o hctx kh√¥ng kh·∫£ d·ª•ng
```

Qu√° tr√¨nh th·ª±c thi hctx (hw queue) `blk_mq_run_hw_queue` c√≥ th·ªÉ l√† sync (ƒë·ªìng b·ªô) ho·∫∑c async (b·∫•t ƒë·ªìng b·ªô). Trong c√°c ƒëi·ªÅu ki·ªán ph√¢n nh√°nh tr√™n:

- N·∫øu l√† case4, th√¨ l√† sync
- N·∫øu l√† case5, th√¨ l√† async

```c
blk_mq_run_hw_queue
    __blk_mq_delay_run_hw_queue
        __blk_mq_run_hw_queue
            blk_mq_sched_dispatch_requests
                // ƒê√¢y l√† sync entry point

blk_mq_sched_dispatch_requests(hctx)
    LIST_HEAD(rq_list)
    if hctx->dispatch is not empty
        list_splice_init(hctx->dispatch, rq_list)
            // Trong hctx instance, dispatch field l√† request queue c√≥ √Ω nghƒ©a th·ª±c ch·∫•t, 
            // b√¢y gi·ªù chuy·ªÉn giao cho rq_list ƒë∆∞·ª£c allocate tr√™n stack
    // Chia th√†nh v√†i tr∆∞·ªùng h·ª£p:
    // 1. blk_mq_dispatch_rq_list
        // ∆Øu ti√™n dispatch c√°c request tr∆∞·ªõc ƒë√≥ trong hctx ch∆∞a ƒë∆∞·ª£c dispatch ƒë·∫øn driver
    // 2. blk_mq_do_dispatch_sched
        // Chuy·ªÉn request trong sched queue v√†o rq_list, sau ƒë√≥ g·ªçi blk_mq_dispatch_rq_list, dispatch ƒë·∫øn driver
    // 3. blk_mq_do_dispatch_ctx
        // Trong tr∆∞·ªùng h·ª£p hctx busy, tr·ª±c ti·∫øp chuy·ªÉn rq c·ªßa ctx v√†o rq_list, sau ƒë√≥ dispatch cho driver
        // V√¨ l√Ω do c√¥ng b·∫±ng, s·∫Ω xem x√©t th·ª±c hi·ªán dispatch lu√¢n phi√™n cho nhi·ªÅu ctx
    // 4. blk_mq_dispatch_rq_list
        // C√°c tr∆∞·ªùng h·ª£p kh√°c dispatch request trong rq_list cho driver x·ª≠ l√Ω
```

Qu√° tr√¨nh n√†y kh√° ph·ª©c t·∫°p, nh√¨n t·ªïng th·ªÉ l√† ph√¢n chia theo ƒë·∫∑c ƒëi·ªÉm c·ªßa IO:

- **Thi·∫øt b·ªã**: Single queue hay multi-queue
- **Hardware queue (hctx)**: Busy hay idle
- **IO scheduler (elevator)**: C√≥ attach v√†o blk-mq hay kh√¥ng
- **Plug operation**: C√≥ enable plug hay kh√¥ng
- **Request type**: Sync hay async

Ph√¢n lo·∫°i x·ª≠ l√Ω l√† d·ª±a tr√™n c√°c ƒë·∫∑c ƒëi·ªÉm tr√™n ƒë·ªÉ t·ªï h·ª£p th√†nh c√°c nh√°nh path kh√°c nhau:

1. C√≥ urgent kh√¥ng, urgent th√¨ dispatch tr·ª±c ti·∫øp, flush->hctx
2. C√≥ ph·∫£i slow device kh√¥ng, t·ª©c l√† single queue v√† plug
3. Multi-queue plug
4. IO scheduler attach, bi·ªÉu th·ªã mutual exclusive v·ªõi ctx
5. plug v√† nomerges v√† kh√¥ng attach, v·ªÅ c∆° b·∫£n l√† √Ω nghƒ©a corner case c·ªßa c√°c ƒëi·ªÅu ki·ªán tr∆∞·ªõc
6. C√≥ skip ctx kh√¥ng, t·ª©c l√† kh√¥ng c√≥ IO scheduler attach, device multi-queue, hctx idle v√† IO sync
7. Default branch, tr∆∞·ªùng h·ª£p kh√¥ng c√≥ IO sched v√† kh√¥ng c√≥ plug
8. Hidden branch, l·∫ßn x·ª≠ l√Ω IO n√†y th·∫•t b·∫°i, l·∫ßn sau x·ª≠ l√Ω theo tr∆∞·ªùng h·ª£p urgent

K·∫øt qu·∫£ sau khi t·ªï h·ª£p th∆∞·ªùng tu√¢n theo th·ª© t·ª± queue nh∆∞ sau:

```
        -> flush ------------------------>
request -> [pluglist] -> [ctx || sched] -> hctx -> drivers/...
```

M·ªôt s·ªë ghi ch√∫:

- IO scheduler queue v√† software queue l√† quan h·ªá mutual exclusive. IO scheduler attach v√†o blk-mq th√¨ kh√¥ng s·ª≠ d·ª•ng ctx
- plug l√† t√πy ch·ªçn
- Khi hctx idle, m·ªôt ph·∫ßn request c√≥ th·ªÉ skip ctx v√† ƒëi th·∫≥ng ƒë·∫øn hctx (v√≠ d·ª• path 6)

Theo k·∫øt qu·∫£ ph√¢n t√≠ch c·ªßa ng∆∞·ªùi ƒëi tr∆∞·ªõc (v√¨ m·ªôt s·ªë l√Ω do, t√¥i kh√¥ng th·ªÉ cung c·∫•p reference link), c√°c ƒëi·ªÅu ki·ªán sau √°p d·ª•ng cho default path (7):

- IO request c·ªßa EMMC device (high-speed kh√¥ng plug single queue)
- NVME device, async IO request
- NVME device, sync IO request, v√† hctx busy

---

Quay l·∫°i `blk_mq_run_hw_queue`, async flow s·∫Ω c√≥ entry point h∆°i kh√°c:

```c
blk_mq_run_hw_queue
    __blk_mq_delay_run_hw_queue
-       __blk_mq_run_hw_queue
+       kblockd_mod_delayed_work_on
+       mod_delayed_work_on(cpu = hctx_next_cpu, kblockd_workqueue, dwork = hctx->run_work, delay = 0)
```

Task assignment ƒë∆∞·ª£c ƒëƒÉng k√Ω trong initialization flow tr∆∞·ªõc:

```c
blk_mq_init_hctx
    ...
    INIT_DELAYED_WORK(&hctx->run_work, blk_mq_run_work_fn)
```

·ªû ƒë√¢y li√™n quan ƒë·∫øn c∆° ch·∫ø `workqueue`, ch√∫ √Ω context s·ª≠ d·ª•ng c·ªßa n√≥:

- **Thread instance**: `kblockd`
- **Task type**: `delayed_work` type c·ªßa `hctx->run_work`
- **Specific task**: `run_work` t∆∞∆°ng ·ª©ng v·ªõi `blk_mq_run_work_fn`

```c
blk_mq_run_work_fn(work)
    hctx = container_of(work, ...)
    __blk_mq_run_hw_queue(hctx)
```
Th·ª±c t·∫ø `blk_mq_run_work_fn` ƒëi v√≤ng quanh r·ªìi l·∫°i quay v·ªÅ sync flow, ch·ªâ kh√°c l√† ƒë∆∞·ª£c giao cho `kblockd` x·ª≠ l√Ω.

## 6. Chi ti·∫øt kh√¥ng quan tr·ªçng

- Hardware queue c·ªßa `blk-mq` kh√¥ng li√™n quan ƒë·∫øn queue ·ªü driver layer.
- M·∫∑c d√π software queue th∆∞·ªùng ƒë∆∞·ª£c coi l√† per-cpu level, nh∆∞ng maintainer c≈©ng ch·ªâ ra: n·∫øu trong ki·∫øn tr√∫c NUMA, L3 cache ƒë·ªß l·ªõn th√¨ software queue c√≥ th·ªÉ ƒë∆∞·ª£c thi·∫øt l·∫≠p ·ªü per-socket level, nh∆∞ v·∫≠y c√≥ th·ªÉ ƒë·∫°t ƒë∆∞·ª£c ƒëi·ªÉm c√¢n b·∫±ng gi·ªØa cache-friendly v√† lock contention.
- S·ªë l∆∞·ª£ng hardware queue trong c√°c tr∆∞·ªùng h·ª£p kh√°c nhau c√≥ th·ªÉ g√¢y nh·∫ßm l·∫´n, v√¨ kernel s·∫Ω coi nh·ªØng hardware queue v∆∞·ª£t qu√° s·ªë CPU l√† kh√¥ng t·ªìn t·∫°i (do ph·∫ßn v∆∞·ª£t qu√° kh√¥ng c√≥ √Ω nghƒ©a), n√™n kh√¥ng ho√†n to√†n b·∫±ng s·ªë hardware queue theo nghƒ©a ph·∫ßn c·ª©ng.
- Tag tuy ƒë∆∞·ª£c hardware queue s·ª≠ d·ª•ng, nh∆∞ng ƒë·ªô d√†i th·ª±c t·∫ø c·ªßa `blk_mq_tags` ƒë∆∞·ª£c t√≠nh theo s·ªë CPU.
- S·ªë `request` t∆∞∆°ng ·ª©ng v·ªõi tag tuy l√† s·ªë queue depth m√† `set` cung c·∫•p, nh∆∞ng m·ªói l·∫ßn allocation th·∫•t b·∫°i s·∫Ω th·ª≠ gi·∫£m queue depth m·ªôt n·ª≠a, ƒëi·ªÅu n√†y c≈©ng s·∫Ω ·∫£nh h∆∞·ªüng th·ª±c t·∫ø ƒë·∫øn `set->queue_depth`.
- M·ªói instance `request` ƒë∆∞·ª£c pre-allocate th·ª±c t·∫ø c√≤n ch·ª©a payload m√† driver layer c·∫ßn.
- `ns->queue` ch√≠nh l√† instance `request_queue`.
- Trong qu√° tr√¨nh submit IO, `generic_make_request` ƒë√£ b·ªã lo·∫°i b·ªè c√πng v·ªõi SQ framework, thay th·∫ø b·∫±ng `blk_mq_submit_bio`, nh∆∞ng b·∫£n ch·∫•t kh√¥ng thay ƒë·ªïi.
- Trong qu√° tr√¨nh x·ª≠ l√Ω IO, case4 ƒëi sync ƒë·ªÉ ch·∫°y hctx l√† v√¨ IO operation ban ƒë·∫ßu ƒë√£ l√† sync type.
- "Dispatch ƒë·∫øn driver layer" c√≥ nghƒ©a l√† cu·ªëi c√πng ƒë∆∞·ª£c g·ªçi b·ªüi interface `queue_rq`, implementation c·ª• th·ªÉ c√≥ li√™n quan m·∫°nh v·ªõi [driver](https://elixir.bootlin.com/linux/v4.18.20/source/drivers/nvme/host/pci.c#L1524).

## 7. M·ªôt s·ªë khuy·∫øn ngh·ªã s·ª≠ d·ª•ng

**Q. T√¥i s·ª≠ d·ª•ng thi·∫øt b·ªã single-queue truy·ªÅn th·ªëng, c√≥ c·∫ßn quay v·ªÅ single-queue framework kh√¥ng?**

A. Kh√¥ng c·∫ßn. M·ªôt l√† `blk-mq` trong th·ª±c t·∫ø v·∫´n c√≥ hi·ªáu su·∫•t cao h∆°n `sq` framework, hai l√† t·ª´ kernel version 5.0 tr·ªü ƒëi ƒë√£ x√≥a ho√†n to√†n `sq` framework.

---

**Q. Multi-queue framework c√≥ c·∫ßn s·ª≠ d·ª•ng IO scheduler kh√¥ng?**

A. N·∫øu l√† HDD th√¨ c·∫ßn. ƒê·ªëi v·ªõi SSD (ƒë·ªß hi·ªáu su·∫•t cao), v√≠ d·ª• b·∫°n c·∫ßn fair scheduling ho·∫∑c l√†m QoS th√¨ c√≥ th·ªÉ d√πng ƒë∆∞·ª£c, nh∆∞ng ch·ªâ x√©t v·ªÅ hi·ªáu su·∫•t th√¨ ƒë√¢y l√† ch·ªß ƒë·ªÅ m·ªü ([kh√¥ng ph·ª•c th√¨ ch·∫°y benchmark](https://zhuanlan.zhihu.com/p/401165968) th√¥i).

---

**Q. N·∫øu th·ª±c s·ª± c·∫ßn ch·ªçn IO scheduler, n√™n ch·ªçn nh∆∞ th·∫ø n√†o?**

A. [T√†i li·ªáu RedHat](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-the-disk-scheduler_monitoring-and-managing-system-status-and-performance) ƒë∆∞a ra m·ªôt s·ªë l·ª±a ch·ªçn theo scenario, ƒë·ªÉ ti·∫øt ki·ªám IO c·ªßa b·∫°n, t√¥i t√≥m t·∫Øt c√°c ƒëi·ªÉm ch√≠nh:

| Use case | Disk scheduler |
|----------|----------------|
| **Traditional HDD v·ªõi SCSI interface** | S·ª≠ d·ª•ng mq-deadline ho·∫∑c bfq |
| **High-performance SSD ho·∫∑c CPU-bound system v·ªõi fast storage** | S·ª≠ d·ª•ng none, ƒë·∫∑c bi·ªát khi ch·∫°y enterprise applications. Ho·∫∑c c√≥ th·ªÉ d√πng kyber |
| **Desktop ho·∫∑c interactive tasks** | S·ª≠ d·ª•ng bfq |
| **Virtual guest** | S·ª≠ d·ª•ng mq-deadline. V·ªõi HBA driver h·ªó tr·ª£ multi-queue, d√πng none |

---

**Q. C√°c t√πy ch·ªçn scheduler n√†y qu√° naive, c√≥ t√πy ch·ªçn tuning pro h∆°n kh√¥ng?**

A. T√¥i c√≤n qu√° k√©m... ƒê√¢y l√† m·ªôt [t√†i li·ªáu RedHat kh√°c](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/factors-affecting-i-o-and-file-system-performance_monitoring-and-managing-system-status-and-performance#generic-block-device-tuning-parameters_factors-affecting-i-o-and-file-system-performance) c√≥ th·ªÉ tham kh·∫£o.

## 8. TODO (ƒê√£ b·ªè d·ªü üïä)

Kh√¥ng c√≥ g√¨ b·∫•t ng·ªù khi l·∫°i b·ªè d·ªü kh√° nhi·ªÅu n·ªôi dung:

- Lu·ªìng ho√†n th√†nh IO (li√™n quan ƒë·∫øn interrupt).
- Ho√†n thi·ªán chi ti·∫øt lu·ªìng x·ª≠ l√Ω IO.
- Lu·ªìng merge, split IO.
- C·∫≠p nh·∫≠t kernel version.

## 9. T√†i li·ªáu tham kh·∫£o

- [Multi-Queue Block IO Queueing Mechanism (blk-mq) ‚Äì The Linux Kernel Archives](https://www.kernel.org/doc/html/latest/_sources/block/blk-mq.rst.txt)
- [Linux Block IO: Introducing Multi-queue SSD Access on Multi-core Systems](https://kernel.dk/systor13-final18.pdf)
- [Chapter 11. Setting the disk scheduler ‚Äì Red Hat Customer Portal](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-the-disk-scheduler_monitoring-and-managing-system-status-and-performance)
- [Chapter 32. Factors affecting I/O and file system performance ‚Äì Red Hat Customer Portal](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/factors-affecting-i-o-and-file-system-performance_monitoring-and-managing-system-status-and-performance#generic-block-device-tuning-parameters_factors-affecting-i-o-and-file-system-performance)
- [An Introduction to the Linux Kernel Block I/O Stack ‚Äì IBM](https://mageta.org/_downloads/e303f3c9e01d19e00b648c02d08b8c70/an-introduction-to-the-linux-kernel-block-io-stack.2021v04.pdf)
